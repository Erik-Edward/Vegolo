═══════════════════════════════════════════════════════════════════════════
  GEMMA 3N TOKENIZER INTEGRATION CHECKLIST
═══════════════════════════════════════════════════════════════════════════

Project: Vegolo
Date: October 19, 2025
Tokenizer: Gemma 3n SentencePiece (tokenizer.model)

───────────────────────────────────────────────────────────────────────────
PHASE 1: AUTHENTICATION & DOWNLOAD
───────────────────────────────────────────────────────────────────────────

[ ] 1.1 Install Hugging Face CLI
    Command: pip install huggingface_hub

[ ] 1.2 Authenticate with Hugging Face
    Command: huggingface-cli login
    Enter your access token when prompted

[ ] 1.3 Accept Gemma Terms of Use
    URL: https://huggingface.co/google/gemma-3n-E4B-it
    Action: Click "Agree and access repository"

[ ] 1.4 Download tokenizer using script
    Command: ./download_tokenizer.sh
    Alternative: python3 download_tokenizer.py

[ ] 1.5 Verify download success
    Location: lib/core/ai/tokenizers/gemma-3n-tokenizer.model
    Size: 4,696,020 bytes (exactly)
    SHA-256: (computed by script)

───────────────────────────────────────────────────────────────────────────
PHASE 2: MANIFEST INTEGRATION
───────────────────────────────────────────────────────────────────────────

[ ] 2.1 Review manifest_patch.json
    Check: SHA-256 field is populated (not "COMPUTE_AFTER_DOWNLOAD")
    Check: Size is 4696020 bytes

[ ] 2.2 Backup current manifest
    Command: cp lib/core/ai/model_manifest.json lib/core/ai/model_manifest.json.backup

[ ] 2.3 Apply patch to lib/core/ai/model_manifest.json
    Update: variants[*].files[type == "tokenizer"] entries
    Fields: path, sha256, size_bytes

[ ] 2.4 Verify manifest syntax
    Command: cat lib/core/ai/model_manifest.json | python3 -m json.tool

───────────────────────────────────────────────────────────────────────────
PHASE 3: LEGAL COMPLIANCE
───────────────────────────────────────────────────────────────────────────

[ ] 3.1 Review Gemma Terms of Use
    URL: https://ai.google.dev/gemma/terms
    Saved: /tmp/gemma-terms.html

[ ] 3.2 Review Prohibited Use Policy
    URL: https://ai.google.dev/gemma/prohibited_use_policy
    Saved: /tmp/gemma-prohibited.html

[ ] 3.3 Add required notice to app
    Source: GEMMA_LEGAL_NOTICES.txt
    Text: "Gemma is provided under and subject to the Gemma Terms of Use 
           found at https://ai.google.dev/gemma/terms"

[ ] 3.4 Add legal notice to app screens
    Locations to update:
    [ ] About screen
    [ ] Legal/Licenses screen
    [ ] Settings screen (if applicable)
    [ ] App store description (recommended)

[ ] 3.5 Document prohibited uses in internal docs
    Ensure team is aware of restrictions

───────────────────────────────────────────────────────────────────────────
PHASE 4: CODE INTEGRATION
───────────────────────────────────────────────────────────────────────────

[ ] 4.1 Update ModelManager to load tokenizer
    File: lib/core/ai/model_manager.dart
    Action: Add tokenizer loading logic

[ ] 4.2 Implement checksum verification
    File: lib/core/ai/model_manager.dart
    Action: Verify SHA-256 before use

[ ] 4.3 Update GemmaService to use tokenizer
    File: lib/core/ai/gemma_service.dart
    Action: Initialize with tokenizer path

[ ] 4.4 Handle tokenizer loading errors gracefully
    Scenarios: Missing file, checksum mismatch, load failure

───────────────────────────────────────────────────────────────────────────
PHASE 5: TESTING
───────────────────────────────────────────────────────────────────────────

[ ] 5.1 Unit test: Tokenizer file exists
    Test: File presence check

[ ] 5.2 Unit test: Tokenizer file size
    Expected: 4,696,020 bytes exactly

[ ] 5.3 Unit test: Tokenizer checksum verification
    Expected: SHA-256 from manifest

[ ] 5.4 Unit test: Tokenizer loads successfully
    Test: ModelManager.loadTokenizer()

[ ] 5.5 Integration test: Tokenize sample text
    Input: "gelatin, sugar, water"
    Output: Token IDs

[ ] 5.6 Integration test: Full analysis pipeline
    Test: Camera → OCR → Tokenize → AI inference

[ ] 5.7 Test on low-memory devices
    Target: Devices with <4GB RAM

[ ] 5.8 Test error handling
    Scenarios: Missing file, corrupt file, wrong checksum

───────────────────────────────────────────────────────────────────────────
PHASE 6: DOCUMENTATION
───────────────────────────────────────────────────────────────────────────

[ ] 6.1 Update AGENTS.md (if needed)
    Document: Tokenizer version, source, SHA-256

[ ] 6.2 Update README.md
    Add: Attribution and licensing info

[ ] 6.3 Update build/deployment docs
    Document: Where tokenizer file must be placed

[ ] 6.4 Archive these deliverables
    Move to: docs/tokenizer/ or similar
    Files: All generated .md, .json, .sh, .py files

[ ] 6.5 Add to .gitignore (if not tracking)
    Path: lib/core/ai/tokenizers/*.model
    (Or commit if you want it in version control)

───────────────────────────────────────────────────────────────────────────
PHASE 7: DEPLOYMENT PREPARATION
───────────────────────────────────────────────────────────────────────────

[ ] 7.1 Test on physical Android devices
    Variants: Low-end, mid-range, high-end

[ ] 7.2 Test on physical iOS devices
    Variants: iPhone SE, iPhone 12+, iPad

[ ] 7.3 Verify app size increase
    Added: ~4.5 MB (tokenizer only)

[ ] 7.4 Performance profiling
    Metrics: Load time, memory usage, battery impact

[ ] 7.5 Update app store assets (if needed)
    Screenshots, descriptions mentioning Gemma

[ ] 7.6 Prepare app store legal text
    Include: Required Gemma attribution

───────────────────────────────────────────────────────────────────────────
PHASE 8: QUALITY ASSURANCE
───────────────────────────────────────────────────────────────────────────

[ ] 8.1 Code review
    Reviewers: _______________
    Date: _______________

[ ] 8.2 Security review
    Focus: File integrity, checksum validation

[ ] 8.3 Legal review (optional but recommended)
    Verify: Compliance with Gemma terms

[ ] 8.4 Privacy review
    Ensure: On-device processing, no data leaks

[ ] 8.5 Accessibility review
    Check: Error messages are clear and helpful

───────────────────────────────────────────────────────────────────────────
VERIFICATION MATRIX
───────────────────────────────────────────────────────────────────────────

Tokenizer Verification:
[ ] File exists at: lib/core/ai/tokenizers/gemma-3n-tokenizer.model
[ ] File size: 4,696,020 bytes (exactly)
[ ] SHA-256: ___________________________________ (from manifest)
[ ] Format: SentencePiece (.model)
[ ] Source: google/gemma-3n-E4B-it (official Google repo)

Manifest Verification:
[ ] manifest.json contains tokenizer entry
[ ] SHA-256 matches actual file
[ ] Size matches actual file (4,696,020 bytes)
[ ] Path is: tokenizers/gemma-3n-tokenizer.model

Legal Verification:
[ ] Required notice added to app
[ ] Terms of Use URL included
[ ] Prohibited Use Policy reviewed
[ ] Team aware of restrictions
[ ] App store listings updated

Code Verification:
[ ] Tokenizer loads without errors
[ ] Checksum verification works
[ ] Error handling in place
[ ] Tests passing (unit + integration)

───────────────────────────────────────────────────────────────────────────
SIGN-OFF
───────────────────────────────────────────────────────────────────────────

Developer:   _______________  Date: _______________
             (Name)

Reviewer:    _______________  Date: _______________
             (Name)

QA:          _______________  Date: _______________
             (Name)

Legal:       _______________  Date: _______________
             (Name, if applicable)

───────────────────────────────────────────────────────────────────────────
NOTES
───────────────────────────────────────────────────────────────────────────















───────────────────────────────────────────────────────────────────────────
END OF CHECKLIST
───────────────────────────────────────────────────────────────────────────
