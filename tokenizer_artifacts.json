[
    {
        "repo": "google/gemma-3n-E4B-it",
        "file_path": "tokenizer.model",
        "description": "Official Gemma 3n SentencePiece tokenizer (E4B variant)",
        "size_bytes": 4696020,
        "sha256": "ea5f0cc48abfbfc04d14562270a32e02149a3e7035f368cc5a462786f4a59961",
        "lfs_oid": "ea5f0cc48abfbfc04d14562270a32e02149a3e7035f368cc5a462786f4a59961",
        "commit_or_revision": "main",
        "license_or_terms_link": "https://ai.google.dev/gemma/terms",
        "repo_url": "https://huggingface.co/google/gemma-3n-E4B-it",
        "download_url": "https://huggingface.co/google/gemma-3n-E4B-it/resolve/main/tokenizer.model",
        "notes": "Requires accepting Gemma Terms of Use. This is the primary tokenizer for instruction-tuned E4B variant.",
        "alternative_formats": {
            "tokenizer.json": {
                "size_bytes": 33442559,
                "lfs_oid": "c4c19736bf24d1c6805cf49340e31bd02c70fb7857a2cb31065c90c2b5719c4e",
                "description": "Hugging Face Tokenizers fast format (larger)"
            },
            "tokenizer_config.json": {
                "size_bytes": 1202311,
                "description": "Tokenizer configuration"
            },
            "special_tokens_map.json": {
                "size_bytes": 769,
                "description": "Special tokens mapping"
            }
        }
    },
    {
        "repo": "google/gemma-3n-E2B-it",
        "file_path": "tokenizer.model",
        "description": "Official Gemma 3n SentencePiece tokenizer (E2B variant)",
        "size_bytes": 4696020,
        "sha256": "ea5f0cc48abfbfc04d14562270a32e02149a3e7035f368cc5a462786f4a59961",
        "lfs_oid": "ea5f0cc48abfbfc04d14562270a32e02149a3e7035f368cc5a462786f4a59961",
        "commit_or_revision": "main",
        "license_or_terms_link": "https://ai.google.dev/gemma/terms",
        "repo_url": "https://huggingface.co/google/gemma-3n-E2B-it",
        "download_url": "https://huggingface.co/google/gemma-3n-E2B-it/resolve/main/tokenizer.model",
        "notes": "Same tokenizer as E4B variant. Requires accepting Gemma Terms of Use."
    }
]
